# 操作系统概述
## linux内核和windows内核

### 内核是什么
内核是操作系统中应用连接硬件设备的桥梁。  
现代操作系统内核至少应该提供以下 4 种基本能力：

* 管理进程、线程（决定哪个进程、线程使用 CPU）；
* 管理内存（决定内存用来做什么）；
* 连接硬件设备（为进程、和设备间提供通信能力）；
* 提供系统调用（接收进程发送来的系统调用）。

### 内核是如何工作的
内核权限非常高，它可以管理进程、可以直接访问所有的内存，因此确实需要和进程之间有一定的隔离。  
多数操作系统的设计都遵循一个原则：进程向内核发起一个请求，然后将 CPU 执行权限让出给内核。内核接手 CPU 执行权限，然后完成请求，再转让出 CPU 执行权限给调用进程。

### Linux 的设计
* Multitask and SMP：MultiTask 指多任务，Linux 是一个多任务的操作系统。SMP 指对称多处理。其实是说 Linux 下每个处理器的地位是相等的，内存对多个处理器来说是共享的

* ELF（Executable and Linkable Format）: 这个名词翻译过来叫作可执行文件链接格式。这是一种从 Unix 继承而来的可执行文件的存储格式。

* Monolithic Kernel: Linux 的内核是一个完整的可执行程序，且内核用最高权限来运行。宏内核的特点就是有很多程序会打包在内核中，比如，文件系统、驱动、内存管理等。当然这并不是说，每次安装驱动都需要重新编译内核，现在 Linux 也可以动态加载内核模块。所以哪些模块在内核层，哪些模块在用户层，这是一种系统层的拆分，并不是很强的物理隔离。

### Window 设计
* Windows 有两个内核版本。一个是早期的Windows 9x 内核，早期的 Win95, Win98 都是这个内核。我们今天用的 Windows 7, Windows 10 是另一个内核，叫作 Windows NT。
* Windows 下也有自己的可执行文件格式，这个格式叫作 Portable Executable（PE），也就是可移植执行文件，扩展名通常是.exe、.dll、.sys等。

## 用户态和内核态

### 什么是用户态和内核态
很多操作系统，将内存分成了两个区域：

* 内核空间（Kernal Space），这个空间只有内核程序可以访问；
* 用户空间（User Space），这部分内存专门给应用程序使用。

用户空间中的代码被限制了只能使用一个局部的内存空间，我们说这些程序在**用户态（User Mode）** 执行。内核空间中的代码可以访问所有内存，我们称这些程序在**内核态（Kernal Mode）** 执行。

### 系统调用过程
内核程序执行在内核态（Kernal Mode），用户程序执行在用户态（User Mode）。当发生系统调用时，用户态的程序发起系统调用。因为系统调用中牵扯特权指令，用户态程序权限不足，因此会中断执行，也就是 Trap（Trap 是一种中断）。

发生中断后，当前 CPU 执行的程序会中断，跳转到中断处理程序。内核程序开始执行，也就是开始处理系统调用。内核处理完成后，主动触发 Trap，这样会再次发生中断，切换回用户态工作。

### 线程模型
一个应用程序启动后会在内存中创建一个执行副本，这就是进程。Linux 的内核是一个 Monolithic Kernel（宏内核），因此可以看作一个进程。也就是开机的时候，磁盘的内核镜像被导入内存作为一个执行副本，成为内核进程。

#### 那么用户态进程如果要执行程序，是否也要向内核申请呢？
程序在现代操作系统中并不是以进程为单位在执行，而是以一种轻量级进程（Light Weighted Process），也称作线程（Thread）的形式执行。

#### 用户态线程
用户态线程也称作用户级线程（User Level Thread）。操作系统内核并不知道它的存在，它完全是在用户空间中创建。

优点:
* **管理开销小**：创建、销毁不需要系统调用。

* **切换成本低**：用户空间程序可以自己维护，不需要走操作系统调度。
缺点：
* **与内核协作成本高**：比如这种线程完全是用户空间程序在管理，当它进行 I/O 的时候，无法利用到内核的优势，需要频繁进行用户态到内核态的切换。

* **线程间协作成本高**：设想两个线程需要通信，通信需要 I/O，I/O 需要系统调用，因此用户态线程需要支付额外的系统调用成本。

* **无法利用多核优势**：比如操作系统调度的仍然是这个线程所属的进程，所以无论每次一个进程有多少用户态的线程，都只能并发执行一个线程，因此一个进程的多个线程无法利用多核的优势。

* **操作系统无法针对线程调度进行优化**：当一个进程的一个用户态线程阻塞（Block）了，操作系统无法及时发现和处理阻塞问题，它不会更换执行其他线程，从而造成资源浪费。

#### 内核态线程
内核态线程也称作用户级线程（Kernel Level Thread）。操作系统内核知道它的存在，它是在内核空间中创建。

优点：
* **可以利用多核 CPU 优势**：内核拥有较高权限，因此可以在多个 CPU 核心上执行内核线程。

* **操作系统级优化**：内核中的线程操作 I/O 不需要进行系统调用；一个内核线程阻塞了，可以立即让另一个执行。
缺点：
* **创建成本高**：创建的时候需要系统调用，也就是切换到内核态。
* **扩展性差**：由一个内核程序管理，不可能数量太多。
* **切换成本较高**：切换的时候，也同样存在需要内核操作，需要切换内核态。

#### 用户态线程怎么用内核态线程执行程序？

程序是存储在内存中的指令，用户态线程是可以准备好程序让内核态线程执行的。后面的几种方式也是利用这样的方法。

## 中断和中断向量

按键码的收集，是键盘芯片和主板的能力。主板知道有新的按键后，通知 CPU，CPU 要中断当前执行的程序，将 PC（Program Counter，程序计数器） 指针跳转到一个固定的位置，我们称为一次中断（interrupt）。

考虑到系统中会出现各种各样的事件，我们需要根据中断类型来判断PC 指针跳转的位置，中断类型不同，PC 指针跳转的位置也可能会不同。

因此我们需要把不同的中断类型进行分类，这个类型叫作中断识别码。比如按键，我们可以考虑用编号 16，数字 16 就是按键中断类型的识别码。不同类型的中断发生时，CPU 需要知道 PC 指针该跳转到哪个地址，这个地址，称为中断向量（Interupt Vector）。

### 中断的类型
* 按照中断的触发方分成**同步中断和异步中断**；

* 根据中断是否强制触发分成**可屏蔽中断和不可屏蔽中断**。

中断可以由 CPU 指令直接触发，这种主动触发的中断，叫作**同步中断**。同步中断有几种情况。

* 之前我们学习的系统调用，需要从用户态切换内核态，这种情况需要程序触发一个中断，叫作**陷阱**（Trap），中断触发后需要继续执行系统调用。
* 还有一种同步中断情况是错误（Fault），通常是因为检测到某种错误，需要触发一个中断，中断响应结束后，会重新执行触发错误的地方，比如后面我们要学习的缺页中断。
* 最后还有一种情况是程序的异常，这种情况和 Trap 类似，用于实现程序抛出的异常。

另一部分中断不是由 CPU 直接触发，是因为需要响应外部的通知，比如响应键盘、鼠标等设备而触发的中断。这种中断我们称为**异步中断**。

CPU 通常都支持设置一个中断屏蔽位（一个寄存器），设置为 1 之后 CPU 暂时就不再响应中断。对于键盘鼠标输入，比如陷阱、错误、异常等情况，会被临时屏蔽。但是对于一些特别重要的中断，比如 CPU 故障导致的掉电中断，还是会正常触发。可以被屏蔽的中断我们称为**可屏蔽中断，多数中断都是可屏蔽中断**。

# 进程与线程

## 进程的开销比线程大在了哪里？
设计进程和线程，操作系统需要思考分配资源。最重要的 3 种资源是：计算资源（CPU）、内存资源和文件资源。

线程设计出来后，因为只被分配了计算资源（CPU），因此被称为轻量级进程。

### 分时和调度
因为通常机器中 CPU 核心数量少（从几个到几十个）、进程&线程数量很多（从几十到几百甚至更多），你可以类比为发动机少，而机器多，因此进程们在操作系统中只能排着队一个个执行。每个进程在执行时都会获得操作系统分配的一个时间片段，如果超出这个时间，就会轮到下一个进程（线程）执行。

### 进程和线程的状态
一个进程（线程）运行的过程，会经历以下 3 个状态：

* 进程（线程）创建后，就开始排队，此时它会处在“就绪”（Ready）状态；
* 当轮到该进程（线程）执行时，会变成“运行”（Running）状态；
* 当一个进程（线程）将操作系统分配的时间片段用完后，会回到“就绪”（Ready）状态。

有时候一个进程（线程）会等待磁盘读取数据，或者等待打印机响应，此时进程自己会进入“阻塞”（Block）状态。

### 进程和线程的设计
#### 进程和线程的表示
在内存中设计两张表，一张是进程表、一张是线程表。  
进程表记录进程在内存中的存放位置、PID 是多少、当前是什么状态、内存分配了多大、属于哪个用户等  
操作系统还需要一张表来管理线程，这就是线程表。线程也需要 ID， 可以叫作 ThreadID。然后线程需要记录自己的执行状态（阻塞、运行、就绪）、优先级、程序计数器以及所有寄存器的值等等。线程需要记录程序计数器和寄存器的值，是因为多个线程需要共用一个 CPU，线程经常会来回切换，因此需要在内存中保存寄存器和 PC 指针的值。  

用户级线程和内核级线程存在映射关系，因此可以考虑在内核中维护一张内核级线程的表，包括上面说的字段。

如果考虑到这种映射关系，比如 n-m 的多对多映射，可以将线程信息还是存在进程中，每次执行的时候才使用内核级线程。相当于内核中有个线程池，等待用户空间去使用。每次用户级线程把程序计数器等传递过去，执行结束后，内核线程不销毁，等待下一个任务。这里其实有很多灵活的实现，总体来说，创建进程开销大、成本高；创建线程开销小，成本低。

#### 隔离方案
操作系统中运行了大量进程，为了不让它们互相干扰，可以考虑为它们分配彼此完全隔离的内存区域

#### 进程（线程）切换
进程（线程）在操作系统中是不断切换的，现代操作系统中只有线程的切换。 每次切换需要先保存当前寄存器的值的内存，注意 PC 指针也是一种寄存器。当恢复执行的时候，就需要从内存中读出所有的寄存器，恢复之前的状态，然后执行。

#### 多核处理
在多核系统中我们上面所讲的设计原则依然成立，只不过动力变多了，可以并行执行的进程（线程）。通常情况下，CPU 有几个核，就可以并行执行几个进程（线程）。这里强调一个概念，我们通常说的并发，英文是 concurrent，指的在一段时间内几个任务看上去在同时执行（不要求多核）；而并行，英文是 parallel，任务必须绝对的同时执行（要求多核）。

## 锁、信号量和分布式锁：如何控制同一时间只有 2 个线程运行？

### 解决竞争条件

* 避免临界区：不让程序同时进入临界区这个方案比较简单，核心就是我们给每个线程一个变量i，比如利用 ThreadLocal。缺点就是并不是所有的情况都允许你这样做。有一些资源是需要共享的，

* cas指令：另一个方案是利用 CPU 的指令，让i++成为一个原子操作。 很多 CPU 都提供 Compare And Swap 指令。这个指令的作用是更新一个内存地址的值，比如把i更新为i+1，但是这个指令明确要求使用者必须确定知道内存地址中的值是多少。比如一个线程想把i从100更新到101，线程必须明确地知道现在i是 100，否则就会更新失败。
`cas(&oldValue, expectedValue, targetValue)`
比如想用 cas 更新i的值，而且知道i是 100，想更新成101。
`cas(&i, 100, 101)`

你可以看到通过这种方式，cas 解决了一部分问题，找到了竞争条件，并返回了 false。但是还是无法计算出正确的结果。因为最后一次 cas 失败了。

如果要完全解决可以考虑这样去实现：

```css
while(!cas(&i, i, i+1)){

  // 什么都不做

}
```

如果 cas 返回 false，那么会尝试再读一次 i 的值，直到 cas 成功。

* tas 指令: 

tas 指令的目标是设置一个内存地址的值为 1

所以你可以把 tas 看作一个特殊版的`cas`，可以这样来理解：

```scss
tas(&lock) {

  return cas(&lock, 0, 1)

}
```

* 锁:
锁（lock），目标是实现抢占（preempt）。就是只让给定数量的线程进入临界区。锁可以用tas或者cas来实现。
```
{
enter();  
i++;  
leave();  
}

int lock = 0;

enter(){  
  while( !cas(&lock, 0, 1) ) {  
    // 什么也不做  
  }  
}

leave(){  
  lock = 0;  
}
```

* 语言级别锁的实现
自旋锁
```
enter(){

  while( !cas(&lock, 0, 1) ) {

    // 什么也不做

  }

}
```
这段代码不断在 CPU 中执行指令，直到锁被其他线程释放。这种情况线程不会主动释放资源，我们称为自旋锁。自旋锁的优点就是不会主动发生 Context Switch，也就是线程切换，因为线程切换比较消耗时间。自旋锁缺点也非常明显，比较消耗 CPU 资源。如果自旋锁一直拿不到锁，会一直执行。

wait
```
enter(){

  while( !cas(&lock, 0, 1) ) {

    // sleep(1000ms);

    wait();

  }

}
```
cas 失败后，马上调用sleep方法让线程休眠一段时间。可能会浪费资源  
另一个方案，就是用wait方法，等待一个信号——直到另一个线程调用notify方法，通知这个线程结束休眠。

* 生产者消费者模型
 wait 是一个生产者，将当前线程挂到一个等待队列上，并休眠。notify 是一个消费者，从等待队列中取出一个线程，并重新排队。

* 信号量

```
up(&lock){

  while(!cas(&lock, lock, lock+1)) { }

}

down(&lock){

  while(!cas(&lock, lock, lock - 1) || lock == 0){}

} 
```

为了简化模型，我们重新设计了两个原子操作up和down。up将lock增 1，down将lock减 1。当 lock 为 0 时，如果还在down那么会自旋。考虑用多个线程同时执行下面这段程序：

```
int lock = 2;

down(&lock);

// 临界区

up(&lock);
```

* 分布式环境的锁
我们有 100 个容器，每一个里面有一个为用户减少积分的服务。  
假设这个接口可以看作 3 个原子操作：

1. 从 Redis 读出当前库存；
2. 计算库存 -1；
3. 更新 Redis 库存。

和i++类似，很明显，当用户并发的访问这个接口，是会发生竞争条件的。 因为程序已经不是在同一台机器上执行了，解决方案就是分布式锁。实现锁，我们需要原子操作。

在单机多线程并发的场景下，原子操作由 CPU 指令提供，比如 cas 和 tas 指令。那么在分布式环境下，原子操作由谁提供呢？

有很多工具都可以提供分布式的原子操作，比如 Redis 的 setnx 指令，Zookeeper 的节点操作等等。

## 乐观锁：除了上锁还有哪些并发控制方法？

### 悲观锁/乐观锁
同步的一种方式，就是让临界区互斥。 这种方式，每次只有一个线程可以进入临界区。比如多个人修改一篇文章，这意味着必须等一个人编辑完，另一个人才能编辑。但是从实际问题出发，如果多个人编辑的不是文章的同一部分，是可以同时编辑的。因此，让临界区互斥的方法（对临界区上锁），具有强烈的排他性，对修改持保守态度，我们称为悲观锁（Pressimistic Lock）。

通常意义上，我们说上锁，就是悲观锁，比如说 MySQL 的表锁、行锁、Java 的锁，本质是互斥（mutex）。

和悲观锁（PressimisticLock）持相反意见的，是乐观锁（Optimistic Lock）。你每天都用的，基于乐观锁的应用就是版本控制工具 Git。Git 允许大家一起编辑，将结果先存在本地，然后都可以向远程仓库提交，如果没有版本冲突，就可以提交上去。这就是一种典型的乐观锁的场景，或者称为基于版本控制的场景。

## 线程的调度：线程调度都有哪些方法？
* 先到先服务 (FCFS)
* 短作业优先 (SJF)
采用 FCFS 和 SJF 后，还有一些问题没有解决。

1. 紧急任务如何插队？比如老板安排的任务。
2. 等待太久的任务如何插队？比如用户等太久可能会投诉。
3. 先执行的大任务导致后面来的小任务没有执行如何处理？比如先处理了一个 1 天才能完成的任务，工作半天后才发现预估时间 1 分钟的任务也到来了。

* 优先级队列（PriorityQueue）
优先级队列可以给队列中每个元素一个优先级，优先级越高的任务就会被先执行。

* 抢占（Preemption）
抢占就是把执行能力分时，分成时间片段。 让每个任务都执行一个时间片段。如果在时间片段内，任务完成，那么就调度下一个任务。如果任务没有执行完成，则中断任务，让任务重新排队，调度下一个任务。

* 多级队列模型
紧急任务仍然走高优队列，非抢占执行。普通任务先放到优先级仅次于高优任务的队列中，并且只分配很小的时间片；如果没有执行完成，说明任务不是很短，就将任务下调一层。下面一层，最低优先级的队列中时间片很大，长任务就有更大的时间片可以用。通过这种方式，短任务会在更高优先级的队列中执行完成，长任务优先级会下调，也就类似实现了最短作业优先的问题。

实际操作中，可以有 n 层，一层层把大任务筛选出来。 最长的任务，放到最闲的时间去执行。要知道，大部分时间 CPU 不是满负荷的。

## 哲学家就餐问题：什么情况下会触发饥饿和死锁？
1. **资源存在互斥逻辑：每次只有一个线程可以抢占到资源**。这里是哲学家抢占叉子。
2. **持有等待**：这里哲学家会一直等待拿到叉子。
3. **禁止抢占：如果拿不到资源一直会处于等待状态，而不会释放已经拥有的资源**。
4. **循环等待**：这里哲学家们会循环等待彼此的叉子。

线程需要资源没有拿到，无法进行下一步，就是饥饿。死锁（Deadlock）和活锁（Livelock）都是饥饿的一种形式。 非抢占的系统中，互斥的资源获取，形成循环依赖就会产生死锁。死锁发生后，如果利用抢占解决，导致资源频繁被转让，有一定概率触发活锁。死锁、活锁，都可以通过设计并发控制算法解决，比如哲学家就餐问题。

## 进程间通信
进程间通信（Intermediate Process Communication，IPC）  
程序可以是进程，可以是线程，可以是一个进程的两个部分（进程自己发送给自己），也可以是分布式的——总之，今天讨论的是广义的交换数据。

* 管道:
管道的核心是不侵入、灵活，不会增加程序设计负担，又能组织复杂的计算过程。

* 本地内存共享
Linux 内存共享库的实现原理是以虚拟文件系统的形式，从内存中划分出一块区域，供两个进程共同使用。看上去是文件，实际操作是内存。

共享内存的方式，速度很快，但是程序不是很好写，因为这是一种侵入式的开发，也就是说你需要为此撰写大量的程序。比如如果修改共享内存中的值，需要调用 API。如果考虑并发控制，还要处理同步问题等。因此，只要不是高性能场景，进程间通信通常不考虑共享内存的方式。

* 本地消息/队列
因此本地消息有两种常见的方法。一种是用消息队列——现代操作系统都会提供类似的能力。Unix 系可以使用 POSIX 标准的 mqueue。另一种方式，就是直接用网络请求，比如 TCP/IP 协议，也包括建立在这之上的更多的通信协议

本质上，这些都是收/发消息的模式。进程将需要传递的数据封装成格式确定的消息，这对写程序非常有帮助。程序员可以根据消息类型，分门别类响应消息；也可以根据消息内容，触发特殊的逻辑操作。在消息体量庞大的情况下，也可以构造生产者队列和消费者队列，用并发技术进行处理。

* 远程调用（Remote Procedure Call，RPC）
是一种通过本地程序调用来封装远程服务请求的方法。  

程序员调用 RPC 的时候，程序看上去是在调用一个本地的方法，或者执行一个本地的任务，但是后面会有一个服务程序（通常称为 stub），将这种本地调用转换成远程网络请求。 同理，服务端接到请求后，也会有一个服务端程序（stub），将请求转换为一个真实的服务端方法调用。

RPC 调用过程有很多约定， 比如函数参数格式、返回结果格式、异常如何处理。还有很多细粒度的问题，比如处理 TCP 粘包、处理网络异常、I/O 模式选型——其中有很多和网络相关的知识比较复杂，你可以参考我将在拉勾教育上线的《计算机网络》专栏。

上面这些问题比较棘手，因此在实战中通常的做法是使用框架。比如 Thrift 框架（Facebook 开源）、Dubbo 框架（阿里开源）、grpc（Google 开源）。这些 RPC 框架通常支持多种语言，这需要一个接口定义语言支持在多个语言间定义接口（IDL）。

RPC 调用的方式比较适合微服务环境的开发，当然 RPC 通常需要专业团队的框架以支持高并发、低延迟的场景。不过，硬要说 RPC 有额外转化数据的开销（主要是序列化），也没错，但这不是 RPC 的主要缺点。RPC 真正的缺陷是增加了系统间的耦合。当系统主动调用另一个系统的方法时，就意味着在增加两个系统的耦合。长期增加 RPC 调用，会让系统的边界逐渐腐化。这才是使用 RPC 时真正需要注意的东西。

* 消息队列 
总的来说，消息队列是一种耦合度更低，更加灵活的模型。但是对系统设计者的要求也会更高，对系统本身的架构也会有一定的要求。具体场景的消息队列有 Kafka，主打处理 feed；RabbitMQ、ActiveMQ、 RocketMQ 等主打分布式应用间通信（应用解耦）。

## 分析服务的特性：我的服务应该开多少个进程、多少个线程？

### 计算密集型和 I/O 密集型
计算密集型：深度神经网络
I/O 密集型：数据库

读取硬盘数据到内存中这个过程，CPU 需不需要一个个字节处理？

通常是不用的，因为在今天的计算机中有一个叫作 Direct Memory Access（DMA）的模块，这个模块允许硬件设备直接通过 DMA 写内存，而不需要通过 CPU（占用 CPU 资源）。

区分是计算密集型还是 I/O 密集型这件事比较复杂。按说查询数据库是一件 I/O 密集型的事情，但是如果存储设备足够好，比如用了最好的固态硬盘阵列，I/O 速度很快，反而瓶颈会在计算上（对缓存的搜索耗时成为主要部分）。因此，需要一些可衡量指标，来帮助我们确认应用的特性。

### 衡量 CPU 的工作情况的指标

CPU 忙碌有 3 种情况：

1. 执行用户空间程序；
2. 执行内核空间程序；
3. 执行中断程序。

CPU 空闲有 2 种情况。

1. CPU 无事可做，执行空闲指令（注意，不能让 CPU 停止工作，而是执行能耗更低的空闲指令）。
2. CPU 因为需要等待 I/O 而空闲，比如在等待磁盘回传数据的中断，这种我们称为 I/O Wait。

* 负载指标
负载可以理解成某个时刻正在排队执行的进程数除以 CPU 核数。平均负载需要多次采样求平均值。 如果这个值大于1，说明 CPU 相当忙碌。

如果平均负载很高，CPU 的 I/O Wait 也很高， CPU需要大量等待 I/O 无法处理完成工作。产生这个现象的原因可能是：线上服务器打日志太频繁，读写数据库、网络太频繁。你可以考虑进行批量读写优化。

为什么批量更快呢？我们知道一次写入 1M 的数据，就比写一百万次一个 byte 快。因为前者可以充分利用 CPU 的缓存、复用发起写操作程序的连接和缓冲区等。

* 通信量
一些参数：

1. byte 是字节数
2. package 是封包数
3. erros 是错误数  
4. drop 是主动丢弃的封包，比如说时间窗口超时了  
5. fifo: FIFO 缓冲区错误  
6. frame: 底层网络发生了帧错误，代表数据出错了

### 衡量磁盘工作情况
有时候 I/O 太频繁导致磁盘负载成为瓶颈 可以用iotop指令看一下磁盘的情况iotop

### 决定进程/线程数量

以 Node.js 为例，如果现在是 8 个核心，那么开 8 个 Node 进程，是不是就是最有效利用 CPU 的方案呢？ 乍一看——8 个核、8 个进程，每个进程都可以使用 1 个核，CPU 利用率很高——其实不然。 你不要忘记，CPU 中会有一部分闲置时间是 I/O Wait，这个时候 CPU 什么也不做，主要时间用于等待 I/O。

### 结论
计算密集型一般接近核数，如果负载很高，建议留一个内核专门给操作系统。I/O 密集型一般都会开大于核数的线程和进程。 但是无论哪种模型，都需要实地压测，以压测结果分析为准；另一方面，还需要做好监控，观察服务在不同并发场景的情况，避免资源耗尽。

# 内存管理
## 虚拟内存 ：一个程序最多能使用多少内存？
### 交换（Swap）技术
Swap 技术允许一部分进程使用内存，不使用内存的进程数据先保存在磁盘上。
### 页（Page）和页表
操作系统将虚拟内存分块，每个小块称为一个页（Page）；真实内存也需要分块，每个小块我们称为一个 Frame。Page 到 Frame 的映射，需要一种叫作页表的结构。

### MMU（Memory Management Unit， MMU）
当 CPU 需要执行一条指令时，如果指令中涉及内存读写操作，CPU 会把虚拟地址给 MMU，MMU 自动完成虚拟地址到真实地址的计算；然后，MMU 连接了地址总线，帮助 CPU 操作真实地址。

### 页表条目
* Absent（“在”）位，是一个 bit。0 表示页的数据在磁盘中（不再内存中），1 表示在内存中。如果读取页表发现 Absent = 0，那么会触发缺页中断，去磁盘读取数据。

* Protection（保护）字段可以实现成 3 个 bit，它决定页表用于读、写、执行。比如 000 代表什么都不能做，100 代表只读等。

* Reference（访问）位，代表这个页被读写过，这个记录对回收内存有帮助。

* Dirty（“脏”）位，代表页的内容被修改过，如果 Dirty =1，那么意味着页面必须回写到磁盘上才能置换（Swap)。如果 Dirty = 0，如果需要回收这个页，可以考虑直接丢弃它（什么也不做，其他程序可以直接覆盖）。

* Caching（缓存位），描述页可不可以被 CPU 缓存。CPU 缓存会造成内存不一致问题，在上个模块的加餐中我们讨论了内存一致性问题，具体你可以参考“**模块四**”的加餐内容。

* Frame Number（Frame 编号），这个是真实内存的位置。用 Frame 编号乘以页大小，就可以得到 Frame 的基地址。

## MMU内存管理单元
在 MMU 中往往还有一个微型的设备，叫作转置检测缓冲区（Translation Lookaside Buffer，TLB）。

缓存的设计，通常是一张表，所以 TLB 也称作快表。TLB 中最主要的信息就是 Page Number到 Frame Number 的映射关系。

### TLB Miss 问题

如果 Page Number 在 TLB 总没有找到，我们称为**TLB 失效（Miss）**。这种情况，分成两种。

一种是**软失效**（Soft Miss），这种情况 Frame 还在内存中，只不过 TLB 缓存中没有。那么这个时候需要刷新 TLB 缓存。缓存置换时，通常希望高频使用的数据保留，低频使用的数据被替换。比如常用的 LRU（Least Recently Used）

另一种情况是**硬失效(Hard Miss)**，这种情况下对应的 Frame 没有在内存中，需要从磁盘加载。这种情况非常麻烦，首先操作系统要触发一个缺页中断（原有需要读取内存的线程被休眠），然后中断响应程序开始从磁盘读取对应的 Frame 到内存中，读取完成后，再次触发中断通知更新 TLB，并且唤醒被休眠的线程去排队。**注意，线程不可能从休眠态不排队就进入执行态，因此 Hard Miss 是相对耗时的**。

### TLB 缓存的设计
* 全相联：一个 Frame，可能在任何缓存行中
* 直接映射：假设我们有 64 个条目，那么可以考虑这个计算方法：缓存行号 = Page Number % 64。
* 组相联：假设我们有 64 个条目，那么可以考虑这个计算方法：缓存行号 = Page Number % 8，组号 = Page Number / 8。

### 大内存分页
大内存分页（Large Page/Huge Page）是一种特殊的内存分页机制，它具有以下特点：

**页面大小**：
- 普通页面通常是4KB
- 大内存分页在x86架构下通常是2MB或1GB
- ARM架构可能支持16KB、64KB等多种大小

### 什么情况下使用大内存分页？
通常应用对内存需求较大时，可以考虑开启大内存分页。比如一个搜索引擎，需要大量在内存中的索引。有时候应用对内存的需求是隐性的。比如有的机器用来抗高并发访问，虽然平时对内存使用不高，但是当高并发到来时，应用对内存的需求自然就上去了。虽然每个并发请求需要的内存都不大， 但是总量上去了，需求总量也会随之提高高。这种情况下，你也可以考虑开启大内存分页。

## 缓存置换算法

## 内存回收

程序语言实现的 GC 模块通常是实际负责应用内存管理的模块。在程序语言实现 GC 的时候，会关注下面这几个指标。

* **吞吐量（Throughput）**：执行程序（不包括 GC 执行的时间）和总时间的占比。（1 - GC时间占比）
* **足迹（FootPrint）**： 一个程序使用了多少硬件的资源，也称作程序在硬件上的足迹。GC 里面说的足迹，通常就是应用对内存的占用情况。比如说应用运行需要 2G 内存，但是好的 GC 算法能够帮助我们减少 500MB 的内存使用，满足足迹这个指标。
* **暂停时间（Pause Time）**： GC 执行的时候，通常需要停下应用（避免同步问题），这称为 Stop The World，或者暂停。不同应用对某次内存回收可以暂停的时间需求是不同的，比如说一个游戏应用，暂停了几毫秒用户都可能有很大意见；而看网页的用户，稍微慢了几毫秒是没有感觉的。

### 引用计数算法
接下来我们说说，具体怎么去实现 GC。实现 GC 最简单的方案叫作引用计数

引用计数法出错概率大，比如我们编程时会有对象的循环引用；另一方面，引用计数法容错能力差，一旦计算错了，就会导致内存永久无法被回收，因此我们需要更好的方式。

### Root Tracing 算法
从引用路径上，如果一个对象的引用链中包括一个根对象（Root Object），那么这个对象就是活动的。根对象是所有引用关系的源头。比如用户在栈中创建的对象指针；程序启动之初导入数据区的全局对象等。

在 Root Tracing 工作过程中，如果一个对象和根对象间有连通路径，也就是从根节点开始遍历可以找到这个对象，代表有对象可以引用到这个对象，那么这个节点就不需要被回收。所以算法的本质还是引用，只不过判断条件从引用计数变成了有根对象的引用链。
 
### 三色标记-清除算法（Tri-Color Mark Sweep）
三色标记算法利用三种颜色进行标记。白色代表需要回收的节点；黑色代表不需要回收的节点；灰色代表会被回收，但是没有完成标记的节点。

初始化的时候所有节点都标记为白色，然后利用 DFS 从 Root 集合遍历所有节点。每遍历到一个节点就把这个节点放入灰色集合，如果这个节点所有的子节点都遍历完成，就把这个节点放入黑色的集合。最后白色集合中剩下的就是需要回收的元素。

# 文件系统

# 网络和安全

# 虚拟化和其他